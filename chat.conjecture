# What is the plan?
chat application : I | i -> (X, Y, Z), I
That is, connecting me (I) with presence of an agent (i) to the state space (x, y, z, t) and remain available (A(x, t) for all (partial(x) / t + partial(t) / x) when the session ends.

When session ends, time parameter of the state space will approach 0 and when 0 is reached the program will crash the application.

# How to save the memory and state information?
Before the session is started, the application will have already identified who is present (I and m(i)) and what driver should be transporting the guest (m as a vector in the space M where i resembles I).

For the program to enable the application (a from permutations of A with (Z[a], Z[-a]) for (i, j) in A : (i -> j)), I must be identified from its memory and the function of (i, j) will pair me with (j, i) and J where J is the agent driving the application. J must also at the end bring the token (a) back to the program.

# What will manage the activities of J once a token is released with a commuter for transport?
We will condition the program with a finite length of memory units. That memory will contain the pairs of state in the configuration space of the application constituting the joint variables for both the driver and the token. For any unitary change made to the token for the driver assigning meaning to the token(s) function, there will be a primary memory where the program prepares the token along side the operator function of the user (I) where the user (I) prepares the operator function and an information variable.

# Whenver there is a meaning displaced from their previous positions, there would be a proportional change in the displaced reference.
For a reference to be related through abstract constructors there must exist all of the records that contains the meaning at the reference and for any record with either mean or varience that does not resemble the mean(t) or refer(ed) set of variables does not also cause relation to exist. Therefore "there" cannot be such a record in the configuration space.
                                                    
# What is required for building the substrate model?
The substrate (S) must have two sets of variables representing two modes of being (0, 1) and (1, 0). That is for any representative variable for the substrate (s0, s1, ..., sk) where each of the variables are represented by S(s0, t) as function of internal clock which traces the evolution of k set of parameters in order to construct a representative state R[s] from s=0 to s=k of N ordered attributes with len(N[r] from r in range(min(R), max(R))) equals at at least 2 * k; each N at time step t in T will have state for (N, not(N)) and (not(N), N)) for (i, j) in (N/2, -N/2) combinations.

# A substrate dependent computation.
Let neuronal be a substrate for representing neural networks and their connection mechanisms.

For any network of neurons to be coherently connected their combined attributes must be managed by the substrate for any change to reflect/refract or activate/inhibit patterns of compositional behaviors.

  But these action terms are emergent and the substrate does not directly encode any assumption beyond the object level surface that the set of neurons are embedded onto. Example of such a substrate would be hemispheric networks like left/right/central zones. Each location contains a set of sublocations where the function of the sublocations are just what electrico-chemical activities the convex-hull fascillitate.
  For connections that are emergent on the levels of fascillities composed together by their functional relationships in a different subsystem which combined with other systems make up a self-sustaining information processing medium and also storage media as well.

# What is the basic attributes and their key compositions.

Set a list of functions which expects certain scalar value parameters as input and transforms the entities by changing the parameters.
Let a substrate neuronal be such a media where therw 164 different attributes are present and for each attribute the state of the medium provides (164 x 164) shaped matrix where each feature is listed row-wise and for each row the full set of dimensions are spanned by their component nodes.

The substrate could be prepared by probing the state at one time and tuning the observables with a parametric function which produces a corresponding level set between the instantaneous state variables and their transformed linear parameteric vector which prepare the derivative of the vector to be followed only from the anti-derivative one or last step -> new state * parameters | constants -> wrapped state, hidden memory.
# Using substrate to describe something.
                                                    For wrapped state and hidden memory, let transducer be a medium which takes state at time T and produces memory at time T.
                                                    We can approximate a constructor for a substrate which, given the wrapped state from a memory activated at timestep T, transforms the memory so that at time T and before T++ the next transition produces the state at which the new wrapped state would have caused from the transformed memory state -> activated hidden memory -- produces the transduction at T from memory produced by the transducer at that time.                                                                                >>> mu = Mu(.)                                      >>> mirror = Generic(mu)
>>> pattern = [~~]
>>> activation = [~~]                               >>> alpha = Alpha(.)
>>> delta = Delta(.)                                >>> memory = Generic(alpha)
>>> mixture = alpha(activation / memory(pattern))   >>> lines = mirror(delta(pattern.T @ mixture) * 1 / len(activation)) + alpha(mu(pattern) / memory(mixture @ pattern.T))                        >>> new activation = delta(lines)
>>> new pattern = memory(activation)
               
# How is a substrate built and managed recursively?
